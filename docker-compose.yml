services:

  nginx:
    image: nginx
    container_name: nginx
    environment:
      - "NGINX_PORT=${NGINX_PORT_INTERNAL}"
    volumes:
      - ./etc/nginx/html:/usr/share/nginx/html:ro

    ports:
      - "${NGINX_PORT_EXTERNAL}:${NGINX_PORT_INTERNAL}"
    healthcheck: {test: "curl -f localhost:${NGINX_PORT_INTERNAL}", interval: 1s, start_period: 30s}

  redpanda:
    image: docker.vectorized.io/vectorized/redpanda:${REDPANDA_VERSION}
    container_name: redpanda
    command:
     - redpanda start
     - --overprovisioned
     - --smp 1
     - --memory 1G
     - --reserve-memory 0M
     - --node-id 0
     - --check=false
     - --kafka-addr 0.0.0.0:${REDPANDA_PORT_KAFKA_INTERNAL}
     - --advertise-kafka-addr redpanda:${REDPANDA_PORT_KAFKA_INTERNAL}
     - --pandaproxy-addr 0.0.0.0:${REDPANDA_PORT_HTTP_INTERNAL}
     - --advertise-pandaproxy-addr redpanda:${REDPANDA_PORT_HTTP_INTERNAL}
     - --set redpanda.enable_transactions=true
     - --set redpanda.enable_idempotence=true
    ports:
     - "${REDPANDA_PORT_SCHEMA_EXTERNAL}:${REDPANDA_PORT_SCHEMA_INTERNAL}"          # Schema Registry port
     - "${REDPANDA_PORT_HTTP_EXTERNAL}:${REDPANDA_PORT_HTTP_INTERNAL}"              # HTTP Proxy port
     - "${REDPANDA_PORT_KAFKA_EXTERNAL}:${REDPANDA_PORT_KAFKA_INTERNAL}"            # Kafka API port
     - "${REDPANDA_PORT_PROMETHEUS_EXTERNAL}:${REDPANDA_PORT_PROMETHEUS_INTERNAL}"  #  Prometheus and HTTP admin port
     - "${REDPANDA_PORT_GRPC_EXTERNAL}:${REDPANDA_PORT_GRPC_INTERNAL}"              # internal RPC port
    healthcheck: {test: "curl -f localhost:${REDPANDA_PORT_PROMETHEUS_INTERNAL}/v1/status/ready", interval: 1s, start_period: 30s}

  redpanda-console:
    image: docker.redpanda.com/vectorized/console:${REDPANDA_CONSOLE_VERSION}
    container_name: redpanda-console
    restart: on-failure
    entrypoint: /bin/sh
    command: -c "echo \"$$CONSOLE_CONFIG_FILE\" > /tmp/config.yml; /app/console"
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["redpanda:${REDPANDA_PORT_KAFKA_INTERNAL}"]
          schemaRegistry:
            enabled: true
            urls: ["http://redpanda:${REDPANDA_PORT_SCHEMA_INTERNAL}"]
        connect:
          enabled: true
          clusters:
            - name: datagen
              url: http://connect:${REDPANDA_PORT_CONNECT_INTERNAL}
    ports:
      - "${REDPANDA_CONSOLE_PORT_EXTERNAL}:${REDPANDA_CONSOLE_PORT_INTERNAL}"
    healthcheck: { test: "curl -f localhost:${REDPANDA_CONSOLE_PORT_INTERNAL}", interval: 1s, start_period: 30s }
    depends_on:
      - redpanda

  connect:
    image: docker.cloudsmith.io/redpanda/connectors/connectors:624ff9e
    hostname: connect
    container_name: connect
    depends_on:
    - redpanda
    ports:
      - "8083:8083"
    environment:
      KAFKA_CONNECT_CONFIGURATION: |
          offset.storage.topic=docker-connect-offsets
          value.converter=org.apache.kafka.connect.json.JsonConverter
          config.storage.topic=docker-connect-configs
          key.converter=org.apache.kafka.connect.json.JsonConverter
          group.id=compose-connect-group
          status.storage.topic=docker-connect-status
          config.storage.replication.factor=1
          offset.storage.replication.factor=1
          status.storage.replication.factor=1
      KAFKA_CONNECT_METRICS_ENABLED: "false"
      KAFKA_CONNECT_BOOTSTRAP_SERVERS: redpanda:9092
      KAFKA_GC_LOG_ENABLED: "false"
      KAFKA_HEAP_OPTS: -Xms128M
      
  materialized:
    image: materialize/materialized:${MATERIALIZE_VERSION}
    container_name: materialized
    command: -w2 --disable-telemetry # -log-filter debug
    depends_on: [redpanda]
    ports:
      - "${MATERIALIZE_PORT_DB_EXTERNAL}:${MATERIALIZE_PORT_DB_INTERNAL}"
    healthcheck: {test: "curl -f localhost:${MATERIALIZE_PORT_DB_INTERNAL}", interval: 1s, start_period: 30s}
    init: true

  materialized-cli:
    image: materialize/cli:${MATERIALIZE_VERSION}
    container_name: materialized-cli
    init: true
    tty: true
    stdin_open: true
    depends_on:
      materialized: { condition: service_healthy }
      redpanda: { condition: service_healthy }

  postgres:
    image: postgres:14
    container_name: postgres
    restart: always
    ports:
      - "${POSTGRES_PORT_EXTERNAL}:${POSTGRES_PORT_INTERNAL}"
    environment:
      PGDATA: /var/lib/postgresql/data
      POSTGRES_DB: ${POSTGRES_DATABASE}
      POSTGRES_USER: ${POSTGRES_USERNAME}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ./etc/postgres/pgdata:/var/lib/postgresql/data
    healthcheck: { test: "pg_isready", interval: 1s, start_period: 30s }

  sqlpad:
    image: sqlpad/sqlpad:6
    container_name: sqlpad
    ports:
      - "${SQLPAD_PORT_EXTERNAL}:${SQLPAD_PORT_INTERNAL}"
    environment:
      SQLPAD_ADMIN: "admin@sqlpad.com"
      SQLPAD_ADMIN_PASSWORD: "admin"
      SQLPAD_APP_LOG_LEVEL: debug
      SQLPAD_WEB_LOG_LEVEL: warn
      SQLPAD_SEED_DATA_PATH: /etc/sqlpad/seed-data
      SQLPAD_CONNECTIONS__pgdemo__name: postgres
      SQLPAD_CONNECTIONS__pgdemo__driver: postgres
      SQLPAD_CONNECTIONS__pgdemo__host: postgres
      SQLPAD_CONNECTIONS__pgdemo__database: ${POSTGRES_DATABASE}
      SQLPAD_CONNECTIONS__pgdemo__username: ${POSTGRES_USERNAME}
      SQLPAD_CONNECTIONS__pgdemo__password: ${POSTGRES_PASSWORD}
      SQLPAD_CONNECTIONS__pgdemo__multiStatementTransactionEnabled: "true"
      SQLPAD_CONNECTIONS__pgdemo__idleTimeoutSeconds: 86400
    volumes:
      - "./etc/sqlpad/seed-data:/etc/sqlpad/seed-data"
    depends_on:
      postgres: { condition: service_healthy }

# https://github.com/osixia/docker-openldap/blob/master/example/docker-compose.yml
  openldap:
    image: bitnami/openldap:2.4.57
    hostname: openldap
    container_name: openldap
    ports:
      - 1389:1389
    environment:
      - LDAP_ADMIN_USERNAME=admin
      - LDAP_ADMIN_PASSWORD=adminpassword
      - LDAP_USERS=user01@metabase.com,user02@metabase.com
      - LDAP_PASSWORDS=password1!,password2!
      - LDAP_PORT_NUMBER=1389
      - LDAP_ROOT=dc=example,dc=org
      - LDAP_USER_DC=users
      - LDAP_GROUP=readers
    # healthcheck: {test: " ldapsearch -H ldap://127.0.0.1:1389 -D dc=example,dc=com -w GoodNewsEveryone -b cn=admin,dc=planetexpress,dc=com", interval: 1s, start_period: 30s}

  metabase:
    image: metabase/metabase:${METABASE_VERSION}
    container_name: metabase
    volumes:
      - "./etc/metabase/data:/metabase-data"
    environment:
      MB_DB_TYPE: postgres
      MB_DB_HOST: postgres
      MB_DB_PORT: ${POSTGRES_PORT_INTERNAL}
      MB_DB_DBNAME: ${POSTGRES_DATABASE}
      MB_DB_USER: ${POSTGRES_USERNAME}
      MB_DB_PASS: ${POSTGRES_PASSWORD}
      MB_LDAP_ENABLED: true
      MB_LDAP_BIND_DN: cn=admin,dc=example,dc=org
      MB_LDAP_GROUP_BASE: cn=readers
      MB_LDAP_HOST: openldap
      MB_LDAP_PASSWORD: adminpassword
      MB_LDAP_PORT: 1389
      MB_LDAP_USER_BASE: ou=users,dc=example,dc=org
      MB_LDAP_ATTRIBUTE_EMAIL: uid
      MB_LDAP_ATTRIBUTE_FIRSTNAME: uid
      MB_LDAP_ATTRIBUTE_LASTNAME: sn
    ports:
      - ${METABASE_PORT_EXTERNAL}:${METABASE_PORT_INTERNAL}
    depends_on:
      materialized: { condition: service_healthy }
      postgres: { condition: service_healthy }
      openldap: { condition: service_healthy }

  # v0.26.5: dbt:1.0.4
  # v0.27.0: dbt:1.2.1
  # latest, db:1.2.1
  dbt:
    image: materialize/dbt-materialize:v0.27.0
          # ghcr.io/dbt-labs/dbt-core:1.3.latest
          # https://github.com/dbt-labs/dbt-core/tree/main/docker
    container_name: dbt
    restart: "no"
    stdin_open: true
    tty: true
    command: bash -c 'dbt run --project-dir=/usr/app; dbt docs generate --project-dir=/usr/app; dbt docs serve --project-dir=/usr/app'
    depends_on:
      - materialized
    volumes:
      - ./etc/dbt/app/dbt/example:/usr/app/
      - ./etc/dbt/profile/:/root/.dbt/
    ports:
      - "${DBT_PORT_EXTERNAL}:${DBT_PORT_INTERNAL}"
    environment:
      DBT_PROFILES_DIR: /root/.dbt
      DBT_PROJECT_DIR: /root/.dbt
      TZ: Etc/GMT+1
